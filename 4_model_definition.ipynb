{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5e1fb1-ab5d-417c-b9fd-156254fb68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install xgboost category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4e0ce-1a7a-4a3b-9959-64c7eef6adcf",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0571530-d9bb-43c1-8c89-b01a939a3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import RobustScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    plot_precision_recall_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0967dc48-0f4d-4187-85f7-3056356ce43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "application = pd.read_parquet(\"data/application.parquet\")\n",
    "credit_record = pd.read_parquet(\"data/credit_record.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab1c5c-80e0-4691-969d-038d37762ca2",
   "metadata": {},
   "source": [
    "## Creating label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e491b189-7474-4518-9924-4e20e9e5bd61",
   "metadata": {},
   "source": [
    "### Month balance & status\n",
    "\n",
    "Month balance: \n",
    "\n",
    "The month of the extracted data is the starting point, backwards, 0 is the current month, -1 is the previous month, and so on\n",
    "\n",
    "Status:\n",
    "\n",
    "0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month\n",
    "\n",
    "<font color=\"red\">I will assume that any overdue of 60 or more days corresponds to a default</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f1c1b8-6ea5-4523-9af9-385938126a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaulted_user_ids = credit_record.query(\"STATUS not in ['0','1','C','X']\")[\"ID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a24413-2eca-4fce-81bd-6f930c0eda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_record_unique = credit_record.drop_duplicates(subset=[\"ID\"],keep=\"last\",ignore_index=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea7ee2-469b-4bc1-9f2a-e9e08aecb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_record_unique[\"LABEL\"] = credit_record[\"ID\"].apply(lambda x: 1 if x in defaulted_user_ids else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e6378-6637-410b-bd5b-7697fa5ad323",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_record_unique[\"LABEL\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92443af5-2adc-4c06-a307-9d0d2d712144",
   "metadata": {},
   "source": [
    "### Merge applications with credit records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0baf324-82b5-4583-b22b-c1a4dfc70654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = application.merge(credit_record_unique[[\"ID\",\"LABEL\"]], how=\"inner\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7143e-8b49-4962-be22-71a6596a7437",
   "metadata": {},
   "source": [
    "## Feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5da16-286b-4c74-9420-d12e1682a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_features = [\n",
    "    \"ID\",\n",
    "    \"LABEL\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3df84-4657-4809-ae55-91e2885b1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d0aa9-1096-4ded-a3b9-9432a787582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features, categorical_features = [], []\n",
    "for feature in df.iloc[:,1:-1].columns:\n",
    "    if feature not in excluded_features and feature not in special_features:\n",
    "        if df[feature].dtype == \"object\":\n",
    "            categorical_features.append(feature)\n",
    "        else:\n",
    "            numeric_features.append(feature)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909ba80-9d4c-4a80-861d-d36f00df13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dba659-190f-4cbe-a687-41467d96ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e41d60-a338-4c62-918e-d1d414346e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = numeric_features + categorical_features + special_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08933ae1-a167-4dca-843d-051dcc4c7b3e",
   "metadata": {},
   "source": [
    "## Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec78fd-e6d5-4158-9f4d-be8610beab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:-1] \n",
    "y = df.iloc[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088588f6-b465-47d7-b5df-ad87018b065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e31008-0ad9-42fa-8312-593caa8e7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f243b6e-472b-4d54-aefe-b3a736f0c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    \"min_child_weight\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"gamma\": [0.5, 1, 1.5, 2, 5],\n",
    "    \"subsample\": np.random.uniform(1, .7, 1),\n",
    "    \"colsample_bytree\": [ 0.3, 0.4, 0.5 , 0.7 ],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"n_estimators\": np.arange(100, 500, 10),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a05b6-5870-44d2-9b9c-be4233381717",
   "metadata": {},
   "source": [
    "## Additional definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddba67d-bbfb-470e-be0d-70a886bfd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values_in_string(text, args_dict):\n",
    "    for key in args_dict.keys():\n",
    "        text = text.replace(key, str(args_dict[key]))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b259f31-b76f-4950-a21d-26f254c262e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedColumnTransformer(ColumnTransformer):       \n",
    "    \"\"\"Wraps a modified version of a ColumnTransformer that includes the column names after having done all the\n",
    "    transformations.\n",
    "        \n",
    "    Args:\n",
    "        transformers (list): List of transformers that are going to be set for the ColumnTransformer inheriting parent\n",
    "    Returns:\n",
    "        None.\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    def __init__(self, transformers):\n",
    "        super().__init__(transformers=transformers)\n",
    "        self.final_features = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        super().fit(X, y=y)\n",
    "        self.final_features = ModifiedColumnTransformer.get_all_column_names(self)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return super().transform(X)\n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        result = super().fit_transform(X, y=y)\n",
    "        self.final_features = ModifiedColumnTransformer.get_all_column_names(self)\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_column_names(column_transformer) -> list:\n",
    "        \"\"\"Extracts the name of the resulting columns of a ColumnTransformer after all the transformations\n",
    "        Args:\n",
    "            column_transformer (ColumnTranformer): ColumnTransformer fitted instance from which to extract the column\n",
    "                names\n",
    "        Returns:\n",
    "            col_name (list): List containing the column names based on the order of the ColumnTransformer transformers\n",
    "        Raises:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        col_name = []\n",
    "        for transformer_in_columns in column_transformer.transformers_:\n",
    "            # print(transformer_in_columns)\n",
    "            raw_col_name = transformer_in_columns[2]\n",
    "            if isinstance(transformer_in_columns[1],Pipeline): \n",
    "                transformer = transformer_in_columns[1].steps[-1][1]\n",
    "            else:\n",
    "                transformer = transformer_in_columns[1]\n",
    "            try:\n",
    "                category_dict = {}\n",
    "                i=0\n",
    "                names = transformer.get_feature_names()\n",
    "                for category in transformer_in_columns[2]:\n",
    "                    category_dict[f\"x{i}\"] = category\n",
    "                    i+=1\n",
    "                names = [replace_values_in_string(name,category_dict) for name in names]\n",
    "                # print(category_dict)\n",
    "            except AttributeError: # if no 'get_feature_names' function, use raw column name\n",
    "                names = raw_col_name\n",
    "            if isinstance(names,np.ndarray): # eg.\n",
    "                col_name += names.tolist()\n",
    "            elif isinstance(names,list):\n",
    "                col_name += names    \n",
    "            elif isinstance(names,str):\n",
    "                col_name.append(names)\n",
    "        return col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bdd930-dd8c-4915-960a-ab40b8887e31",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf98819-c1b7-46c4-be14-45fceeffb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_fields_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"selector\", ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"selector\", \"passthrough\", features)\n",
    "            ], remainder=\"drop\")\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\",missing_values=np.nan, fill_value=np.nan)),\n",
    "        (\"encoder\", WOEEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps = [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", missing_values=np.nan, fill_value=np.nan)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = ModifiedColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", categorical_transformer, categorical_features),\n",
    "        (\"numeric\", numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221518cb-473c-4acf-bb56-a312fb7beac3",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ae071-d079-4559-a6c6-3b23282dfbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = XGBClassifier(objective=\"binary:logistic\", use_label_encoder=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c1af2-d8c4-440f-a55a-6d78ce9ad31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_rs = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"rs\", RandomizedSearchCV(clf_xgb,param_distributions=param_grid,n_iter=100,cv=5,scoring=\"average_precision\", random_state=42, )),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dec5ef1-de4f-4865-b87d-a48f550a6c87",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554c7c6-cb5b-4c23-b1d9-a501695ef905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_xgb_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82122d3-3701-4786-afab-7fecb2f4b2f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f4a01-d7c0-4ad2-8100-6600bc11e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_rs[\"rs\"].best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b7b56-d48f-4509-b931-1bdc622dbac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = clf_xgb_rs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ac110-0873-4ae5-a24e-d9bad303b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.where(y_test_proba[:,1] <= 0.5,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4c134-95d9-4e13-b491-47ad96269f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025b4de-92d2-4d80-adda-4e89ae4afc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_test,y_test_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961752cd-b202-437b-9840-5a6cffba18c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
